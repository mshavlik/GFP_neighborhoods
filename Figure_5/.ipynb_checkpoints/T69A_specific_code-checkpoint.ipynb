{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc942e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcsy import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import FlowCal\n",
    "import scipy.optimize as scio\n",
    "from scipy.stats import poisson\n",
    "import seaborn as sns\n",
    "import colorsys\n",
    "import itertools\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import least_squares\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.patches import Circle\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1147cd49",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ee23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in fcs file and drop unnecessary columns and rename channels to FLx\n",
    "\n",
    "def restructure(data):\n",
    "    #data = DataFrame.from_fcs(fcs_file)\n",
    "    \n",
    "    data = data.drop(['TIME','FSC-A','FSC-H','FSC-W','SSC-A'],axis=1)\n",
    "\n",
    "    data.columns = ['FL1','FL2','FL3','FL4','FL5']\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb43e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration(exp,beads):\n",
    "    s_transformed = FlowCal.transform.to_rfi(beads)\n",
    "    \n",
    "    # Channel 1 calibration\n",
    "    MEFL_values = np.array([0,771,2106,6262,15183,45292,136258,291042])\n",
    "\n",
    "    # Channel 2 calibration\n",
    "    MEPE_values = np.array([0,487,1474,4516,11260,34341,107608,260461])\n",
    "\n",
    "    # Channel 3 calibration\n",
    "    MECY_values = np.array([0,1414,3809,10852,27904,85866,324106,1040895])\n",
    "    \n",
    "    # Channel 4 + 5 calibration\n",
    "    MEAP_values = np.array([0,341,1027,3156,7750,23446,68702,116813])\n",
    "    \n",
    "    \n",
    "    # functions to calibrate to proper units\n",
    "    channel_1 = FlowCal.mef.get_transform_fxn(s_transformed,\n",
    "                                        mef_values=MEFL_values,\n",
    "                                        mef_channels='FL1-A',\n",
    "                                        plot=False)\n",
    "    \n",
    "    \n",
    "    channel_2 = FlowCal.mef.get_transform_fxn(s_transformed,\n",
    "                                        mef_values=MEFL_values,\n",
    "                                        mef_channels='FL2-A',\n",
    "                                        plot=False)\n",
    "\n",
    "    \n",
    "    channel_3 =  FlowCal.mef.get_transform_fxn(s_transformed,\n",
    "                                        mef_values=MECY_values,\n",
    "                                        mef_channels='FL3-A',\n",
    "                                        plot=False)\n",
    "    \n",
    "    channel_4 =  FlowCal.mef.get_transform_fxn(s_transformed,\n",
    "                                        mef_values=MEAP_values,\n",
    "                                        mef_channels='FL4-A',\n",
    "                                        plot=False)\n",
    "    \n",
    "    channel_5 =  FlowCal.mef.get_transform_fxn(s_transformed,\n",
    "                                        mef_values=MEAP_values,\n",
    "                                        mef_channels='FL5-A',\n",
    "                                        plot=False)\n",
    "   \n",
    "\n",
    "    ####### Functions to get bead model data ##### - write as dictionary \n",
    "    ch1_out = FlowCal.mef.get_transform_fxn(s_transformed,\n",
    "                                        mef_values=MEFL_values,\n",
    "                                        mef_channels='FL1-A',\n",
    "                                        plot=False,full_output=True)\n",
    "    \n",
    "    \n",
    "    ch2_out = FlowCal.mef.get_transform_fxn(s_transformed,\n",
    "                                        mef_values=MEFL_values,\n",
    "                                        mef_channels='FL2-A',\n",
    "                                        plot=False,full_output=True)\n",
    "\n",
    "    \n",
    "    ch3_out =  FlowCal.mef.get_transform_fxn(s_transformed,\n",
    "                                        mef_values=MECY_values,\n",
    "                                        mef_channels='FL3-A',\n",
    "                                        plot=False,full_output=True)\n",
    "    \n",
    "    ch4_out =  FlowCal.mef.get_transform_fxn(s_transformed,\n",
    "                                        mef_values=MEAP_values,\n",
    "                                        mef_channels='FL4-A',\n",
    "                                        plot=False,full_output=True)\n",
    "    \n",
    "    ch5_out =  FlowCal.mef.get_transform_fxn(s_transformed,\n",
    "                                        mef_values=MEAP_values,\n",
    "                                        mef_channels='FL5-A',\n",
    "                                        plot=False,full_output=True)\n",
    "    \n",
    "    \n",
    "    cal_fxn_dictionary = {0:list(ch1_out[5]['beads_params'][0][:2]),1:list(ch2_out[5]['beads_params'][0][:2]),\n",
    "                         2:list(ch3_out[5]['beads_params'][0][:2]),3:list(ch4_out[5]['beads_params'][0][:2]),\n",
    "                         4:list(ch5_out[5]['beads_params'][0][:2])}\n",
    "    \n",
    "   \n",
    "    # Apply functions to data\n",
    "    transformed_experiment = FlowCal.transform.to_rfi(exp)\n",
    "    \n",
    "    # Transform experiment\n",
    "    FL1_corrected = channel_1(transformed_experiment,channels='FL1-A')\n",
    "    FL2_corrected = channel_2(transformed_experiment,channels='FL2-A')\n",
    "    FL3_corrected = channel_3(transformed_experiment,channels='FL3-A')\n",
    "    FL4_corrected = channel_4(transformed_experiment,channels='FL4-A')\n",
    "    FL5_corrected = channel_5(transformed_experiment,channels='FL5-A')\n",
    "    \n",
    "    \n",
    "    channels = ['FL1','FL2','FL3','FL4','FL5']\n",
    "    \n",
    "    # Pull all of the right calibrated values for each channel\n",
    "    FL1_list = list(FL1_corrected[:,0])\n",
    "    FL2_list = list(FL2_corrected[:,1])\n",
    "    FL3_list = list(FL3_corrected[:,2])\n",
    "    FL4_list = list(FL4_corrected[:,3])\n",
    "    FL5_list = list(FL5_corrected[:,4])\n",
    "        \n",
    "        \n",
    "    \n",
    "    # List of lists to tie together into a new dictionary\n",
    "    data = [FL1_list,FL2_list,FL3_list,FL4_list,FL5_list]\n",
    "\n",
    "    \n",
    "    # Make the dictionary so we can turn it into a dataframe\n",
    "    dictionary_data = dict(zip(channels,data))\n",
    "    \n",
    "    calibrated_dataframe = pd.DataFrame(dictionary_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return the calibrated data\n",
    "    return calibrated_dataframe, cal_fxn_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(control,experiment):\n",
    "    \n",
    "    # remove autofluorescence signal for each channel\n",
    "    for i in control.columns:\n",
    "        af_list = list(control[i])\n",
    "        af_list.sort()\n",
    "        \n",
    "        # AF is anything but the top 5% of values in the control \n",
    "        cutoff = int(len(af_list) - 0.05*len(af_list))\n",
    "        \n",
    "        # This is the autofluorescence value to remove from our experiment in the given channel\n",
    "        af_value = af_list[cutoff]\n",
    "       \n",
    "       \n",
    "        # Subtract the autofluorescence in our experiment\n",
    "        experiment[i] = experiment[i]-af_value\n",
    "        \n",
    "    \n",
    "    \n",
    "   #### USE THIS AS NEW FUSION PROTEIN CORRECTION STUFF\n",
    "    #### Check if any of our channels are above 0 after AF correction\n",
    "    #### If they are, then keep it. If not, that cell must not have had any protein expressed\n",
    "    keys = list(experiment.columns)\n",
    "    values = [[],[],[],[],[]]\n",
    "\n",
    "    for i in experiment.values:\n",
    "        if any(j>0 for j in i):    #uncomment this line when you have biliverdin and fluorescence from miRFP!\n",
    "            values[0].append(i[0])\n",
    "            values[1].append(i[1])\n",
    "            values[2].append(i[2])\n",
    "            values[3].append(i[3])\n",
    "            values[4].append(i[4])\n",
    "        \n",
    "    answer = pd.DataFrame(dict(zip(keys,values)))\n",
    "\n",
    "        \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(normed_dataframe,max_vector):\n",
    "\n",
    "    # Get rid of channels 4 and 5 for color analysis - should put in some control here where I drop cells that have 0 across\n",
    "    # the board - maybe will do that in normalize function\n",
    "    three_vec = normed_dataframe.drop(['FL4','FL5'],axis=1)\n",
    "    three_vec_values = three_vec.values\n",
    "\n",
    "    # Once fusion is gone, change negative values to just be 0 in the vector\n",
    "    three_vec_values = np.where(three_vec_values<0,0,three_vec_values)\n",
    "\n",
    "    # normalize each channel in the vector to be 0-1, with 1 being the channel with the highest signal. This is crucial for \n",
    "    # the next binning step\n",
    "    for i, vec in enumerate(three_vec_values):\n",
    "        three_vec_values[i] = vec/max(max_vector) \n",
    "\n",
    "    # Some cells were all below autofluorescence and so had 0's in every channel. max=0 means divide by 0 = NaN\n",
    "    # this line will convert nans to 0s\n",
    "    three_vec_values = np.nan_to_num(three_vec_values,nan=0,neginf=0)\n",
    "    \n",
    "    # After dividing by mean and stdev, make things higher at 1\n",
    "    three_vec_values = np.where(three_vec_values > 1,1,three_vec_values) \n",
    "\n",
    "    # make a list dictating all of the bin intervals and make a list to hold the vectors for each bin\n",
    "    #bin_list = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "    bin_list = list(np.arange(0,1.025,0.025))\n",
    "    bin_vec_list = []\n",
    "\n",
    "    \n",
    "    # HSV conversion. Specific to this version of the code. Previous version uses RGB. Note that THIS causes\n",
    "    # some differences in the final neighborhood graph because you do this step, which alters the bins,\n",
    "    # prior to doing any of the linear modeling, based on the bins\n",
    "    for i, vec in enumerate(three_vec_values):\n",
    "        three_vec_values[i] = colorsys.rgb_to_hsv(vec[2],vec[1],vec[0])     \n",
    "        \n",
    "    # for each of the 3 channels \n",
    "    for i in range(3):\n",
    "        #bin_vector = []\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        # make a histogram of each of the channels (i = 1 = all channel 1 values, i = 2 = all channel 2 vals ...)\n",
    "        n,bins,patches = ax.hist(three_vec_values[:,i],bins=bin_list)\n",
    "    \n",
    "        ax.set_title('channel ' + str(i+1))\n",
    "\n",
    "        bin_index = np.digitize(three_vec_values[:,i],bins,right=True)\n",
    "      \n",
    "        bin_vec_list.append(list(bin_index))\n",
    "        \n",
    "    vecs = []\n",
    "    \n",
    "    for i, v in enumerate(list(range(0,len(three_vec['FL1'])))):\n",
    "        vecs.append(tuple([bin_vec_list[0][i]/4,bin_vec_list[1][i]/4,bin_vec_list[2][i]/4]))\n",
    "        \n",
    "    # Assign the channel bins to each cell\n",
    "    three_vec['bin vector'] = vecs\n",
    "    \n",
    "    # This yields a dictionary of how many times we saw each bin [0,0,0],[0,0,.1],[0,0,.2]....\n",
    "    val_counts = dict(three_vec['bin vector'].value_counts())\n",
    "    \n",
    "    sum_counts = sum(val_counts.values())\n",
    "\n",
    "    new_val_counts = {key:val/sum_counts for key, val in val_counts.items()}\n",
    "    \n",
    "    return val_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_mix_model(bin_counts,avg_lambda,lambdas,result_dict):\n",
    "    # Get the thetas from a poisson distribution (for now) given the avg mutation rate and expected for \n",
    "    # each mutation rate (in this case 8 for 8 libraries) - the highest one\n",
    "    thetas = [poisson.pmf(l,avg_lambda) for l in lambdas[:-1]]\n",
    "    \n",
    "    # This last theta represents the highest mutation rate plus anything higher than (e.g. 8 if 8 is the highest mutation rate)\n",
    "    thetas.append(1-sum(thetas))\n",
    "    \n",
    "    \n",
    "    # mutation rate fractions to optimize (e.g. g1, g2, g3 ....g8)\n",
    "    params = [0.001]*len(lambdas)\n",
    "    \n",
    "    # Write objective function to optimize predicted mutation fractions\n",
    "    def objective(params,muts,obs):\n",
    "        pred = sum([params[index]*val for index,val in enumerate(muts)])\n",
    "        \n",
    "        return pred-obs\n",
    "    \n",
    "        \n",
    "    # Least squares function gives the inferred g0,g1,g2... with x.x\n",
    "    ope = 0\n",
    "    for bin_key, counts in bin_counts.items():\n",
    "        x = scio.least_squares(objective,params,bounds=(0,np.inf),args=[thetas,counts])\n",
    "    \n",
    "        \n",
    "        for ind,val in enumerate(x.x):\n",
    "            result_dict[bin_key][ind] += (val*thetas[ind])\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_neighborhood_dict(result_dictionary):\n",
    "    \n",
    "    # Create all the bins for the intervals in the three channels [0,0,0],[0,0,1],[0,0,2]....[10,10,10]\n",
    "    x = list(np.arange(0,10.25,0.25))\n",
    "    xnew = []\n",
    "    for i in x:\n",
    "        xnew.append(np.round(i,2))\n",
    "    all_bins = [p for p in itertools.product(xnew,repeat=3)]\n",
    "\n",
    "    # for every bin, give it a blank dictionary to hold the cells\n",
    "    for i in all_bins:\n",
    "        result_dictionary[i] = {}\n",
    "    \n",
    "    # For each bin and it's empty dictionary, give it a mutation rate key (THIS COULD CHANGE WITH NGS DATA) and set its value to 0\n",
    "    # Basically, for each bin vector, how many cells with a given number of mutations fit that bin vector?\n",
    "    for bins, val in result_dictionary.items():\n",
    "        for i in range(0,7,1):\n",
    "            val[i] = 0\n",
    "        \n",
    "\n",
    "    \n",
    "    return result_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66965a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalize the data to the center ring just being green or red or orange or whatever\n",
    "\n",
    "def norm_ring_data(res,base_color):\n",
    "    \n",
    "    total_list = []\n",
    "    for i in range(7):  #The range here is set based on how many rings I'm making\n",
    "        tot = 0\n",
    "        for value in res.values():\n",
    "            tot += value[i]\n",
    "        total_list.append(tot)\n",
    "    \n",
    "    # Change the list(k)[0] is hue cutoffs here for normalization. list(k)[1] is saturation and list(k)[2] is value\n",
    "    dead = (0,0,0)\n",
    "\n",
    "            \n",
    "    reduction_percent = res[dead][0]/total_list[0]\n",
    "    \n",
    "    \n",
    "    for step, number in res[dead].items():\n",
    "        reduction = number-(reduction_percent*total_list[step])\n",
    "        if reduction > 0:\n",
    "            res[dead][step] = reduction\n",
    "        else:\n",
    "            res[dead][step] = 0\n",
    "    \n",
    "\n",
    "    \n",
    "                    \n",
    "    # Just keep the bins that actually have cells recorded in them\n",
    "    trimmed_dict = {key:value for key, value in res.items() if sum(value.values()) >0}\n",
    "    \n",
    "    return trimmed_dict,res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d37048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ring2(neighborhood_dict,step,radius,hue_amplifier=2,brightness_amplifier=3):\n",
    "    total = 0\n",
    "    for key, value in neighborhood_dict.items():\n",
    "        total += value[step]\n",
    "        \n",
    "    cols = []\n",
    "    fracs = []\n",
    "    brightness = []\n",
    "    \n",
    "\n",
    "    differences = []\n",
    "    hsv_keys = []\n",
    "\n",
    "    full_green = colorsys.rgb_to_hsv(1,0,0)\n",
    "    #green_ref = sum(full_green)\n",
    "    green_ref = (0,1,1)\n",
    "  \n",
    "    for j in neighborhood_dict.keys():\n",
    "        hsv_calc = np.array(j)/10\n",
    "        difference = []\n",
    "        for i,v in enumerate(list(green_ref)):\n",
    "            if i == 0:\n",
    "                difference.append((1+abs(v-hsv_calc[i]))**hue_amplifier)\n",
    "            elif i ==2:\n",
    "                difference.append((1+abs(v-hsv_calc[i]))**brightness_amplifier)\n",
    "            \n",
    "            \n",
    "        differences.append(sum(difference))\n",
    "        hsv_keys.append(tuple(np.array(j)/10))\n",
    "\n",
    "\n",
    "    differences, hsv_keys = zip(*sorted(zip(differences,hsv_keys),reverse=True))\n",
    "    \n",
    "    for hsv in hsv_keys:\n",
    "        brightness.append(hsv[2])\n",
    "    \n",
    "    \n",
    "    \n",
    "    for color in hsv_keys:\n",
    "        original = tuple(np.array(color)*10)\n",
    "        bins = neighborhood_dict[original]\n",
    "        \n",
    "        frac = bins[step]/total\n",
    "        \n",
    "        fracs.append(frac)\n",
    "        #fracs2.append(frac)\n",
    "    \n",
    "\n",
    "    final_hsv = []\n",
    "    final_fracs = []\n",
    "  \n",
    "    dead_frac = 0\n",
    "\n",
    "    for i,v in enumerate(hsv_keys):\n",
    "        if colorsys.hsv_to_rgb(v[0],v[1],1) == (1,1,1):\n",
    "            dead_frac += (fracs[i])\n",
    "        else:\n",
    "            final_hsv.append(v)\n",
    "            final_fracs.append(fracs[i])\n",
    "\n",
    "    final_hsv.insert(0,'gray')\n",
    "    final_fracs.insert(0,dead_frac)\n",
    "\n",
    "    return [final_hsv,final_fracs],[brightness,final_fracs]    # cols and fracs are hues, new_cols and fracs 2 is brightness\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b41790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness_analysis(normed_ring_data,save=False,filepath='library_patterns/brightness_data.pdf'):\n",
    "    #violin plot brightness distribution\n",
    "    hue_list = [[],[],[],[],[],[],[]]\n",
    "    for hsv, rings in normed_ring_data.items():\n",
    "        if hsv != (0,0,0):                               # only things that have color (i.e. not dead)\n",
    "            for ring,num in rings.items():\n",
    "                to_add = np.array([hsv[2]] * int(np.round(num,0)))/10\n",
    "                if len(to_add) > 1:\n",
    "                    for i in to_add:\n",
    "                        hue_list[ring].append(i)\n",
    "\n",
    "    \n",
    "    # bar chart percent of brightness\n",
    "    brightnesses = [np.mean(v) for v in hue_list]\n",
    "    medians = [np.mean(v) for v in hue_list]\n",
    "\n",
    "    zero_ring = max(brightnesses)\n",
    "\n",
    "\n",
    "    xpos = [0,1,2,3,4,5,6]\n",
    "    ypos = []\n",
    "    facecolors = []\n",
    "    confidence_intervals = []\n",
    "    \n",
    "    for i in hue_list:\n",
    "        ypos.append(np.mean(i)) #/zero_ring))\n",
    "        facecolors.append((np.mean(i)/0.408))   # max brightness is 0.41 ish\n",
    "        i.sort()\n",
    "        total_obs = len(i)\n",
    "        lower_idx = int(0.025*total_obs)\n",
    "        upper_idx = int(0.975*total_obs)\n",
    "        \n",
    "        upper_interval = i[upper_idx]\n",
    "        lower_interval = i[lower_idx]\n",
    "        confidence_intervals.append([lower_interval,upper_interval])\n",
    "\n",
    "    #fig, ax = plt.subplots(figsize=(12,5))\n",
    "    \n",
    "    #for i,ring in enumerate(hue_list):\n",
    "     #   if i == 0:\n",
    "      #      sns.kdeplot(ring,ax=ax,color='black',alpha=0.04,label=f'{i}',shade=True)\n",
    "      #  else:\n",
    "       #     sns.kdeplot(ring,ax=ax,color='black',alpha=i/len(hue_list),label=f'{i}')\n",
    "            \n",
    "   # ax.spines['right'].set_visible(False)\n",
    "    #ax.spines['top'].set_visible(False)\n",
    "    #ax.legend(loc='best',ncol=len(hue_list),title='# mutations')\n",
    "    \n",
    "    #ax.set_xlabel('Brightness value',fontsize=14)\n",
    "    #ax.set_ylabel('Frequency',fontsize=14)\n",
    "\n",
    "    \n",
    "    # plot things\n",
    "    fig,ax = plt.subplots(1,1,figsize=(8,5))\n",
    "\n",
    "\n",
    "    #sns.violinplot(data=hue_list,palette=\"viridis_r\",as_cmap=True,ax=ax[0])\n",
    "    sns.violinplot(data=hue_list,ax=ax,color='lightgray',inner='box')\n",
    "    #(GFP)\n",
    "    ax.plot(list(range(len(medians))),[0.3956145568880722,0.32577417647837015,0.36270471581743996,0.393564124720962,0.4047027844405047,0.40296811302842456,0.38940744003252475],'--',color=(0.0,1.0,0.6),linewidth=3.5,label='AncGFP')\n",
    "    #(Anc15)\n",
    "    ax.plot(list(range(len(medians))),[0.25789674497735743,0.137337913715563,0.1259182888471239,0.10996928218366654,0.09684191355026711,0.08890809564966869,0.08539810690423162],'--',color=(1,0,0.6),linewidth=3.5,label='Anc15')\n",
    "\n",
    "    ax.plot(list(range(len(medians))),medians,'-',color='black',linewidth=4)\n",
    "    ax.scatter(list(range(len(medians))),medians,facecolor='white',edgecolor='black',s=80,zorder=100,linewidth=2)\n",
    "    \n",
    "    loc = 1/7\n",
    "    for i in list(range(len(medians))):\n",
    "        ax.axhline(xmin=loc-0.1,xmax=loc-0.01,y=confidence_intervals[i][0],color='blue',linewidth=2)\n",
    "        ax.axhline(xmin=loc-0.1,xmax=loc-0.01,y=confidence_intervals[i][1],color='blue',linewidth=2)\n",
    "        loc += 1/7.1\n",
    "    sns.set_theme(context='notebook', style='ticks')\n",
    "    \n",
    "    #sns.violinplot(data=hue_list,width=0.9,linewidth=2,palette='Blues',ax=ax[0])\n",
    "    ax.set_xticks([0,1,2,3,4,5,6])\n",
    "    ax.set_xticklabels(['0','1','2','3','4','5','6+'])\n",
    "    ax.tick_params(axis='x',labelsize=14)\n",
    "    ax.tick_params(axis='y',labelsize=14)\n",
    "    ax.set_ylabel('Brightness distribution',fontsize=16)\n",
    "    ax.set_xlabel('Mutation ring number',fontsize=16)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_ylim(0,1.05)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #ax[1].bar(xpos,height=ypos,color=[str(x) for x in facecolors],edgecolor='black')\n",
    "    #ax[1].scatter(xpos,ypos,color=[str(x) for x in facecolors],edgecolor='black',s=85,zorder=2)\n",
    "    #ax[1].plot(xpos,ypos,color='black',zorder=1)\n",
    "    #ax[1].set_xticks([0,1,2,3,4,5,6])\n",
    "    #ax[1].set_xticklabels(['0','1','2','3','4','5','6+'])\n",
    "    #ax[1].tick_params(axis='x',labelsize=14)\n",
    "    #ax[1].tick_params(axis='y',labelsize=14)\n",
    "    #ax[1].set_ylim(0,0.405)\n",
    "    #ax[1].set_ylabel('Avg brightness',fontsize=16)\n",
    "    #ax[1].set_xlabel('Mutation ring number',fontsize=16)\n",
    "    #ax[1].spines['right'].set_visible(False)\n",
    "    #ax[1].spines['top'].set_visible(False)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(filepath)\n",
    "    return hue_list,facecolors,medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e830857",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b10c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for folder in glob.iglob('Library_data/Anc15_photoactivation_libraries/*_minutes'):\n",
    "\n",
    "correct_beads = FlowCal.io.FCSData(\"T69A_files/cal/calibration beads.fcs\")\n",
    "#correct_beads = FlowCal.io.FCSData(\"Library_data/Anc15_libraries/calibration beads_Data Source - 1.fcs\")\n",
    "#actual_control = FlowCal.io.FCSData(\"Library_data/Anc15_libraries/Compensation panel/Anc15 control.fcs\")\n",
    "actual_control = FlowCal.io.FCSData(\"T69A_files/cal/negative_control.fcs\")\n",
    "#control,out = calibration(actual_control,correct_beads) \n",
    "\n",
    "# params for lin mix model and things\n",
    "mutation_rates = list(range(7))\n",
    "library_mutation_rates = {0:0,1000:1.06,750:1.29,500:1.55,250:1.4,100:2.04,50:2.7,10:3.14,1:3.42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_sub_ch = correct_beads[:,5:]\n",
    "s_sub_ch2 = actual_control[:,5:]\n",
    "control,out = calibration(s_sub_ch2,s_sub_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898acb3f",
   "metadata": {},
   "source": [
    "# Grab mean and stdev of brightness to normalize all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b10bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelim = {}\n",
    "stackdata = {}\n",
    "res = prep_neighborhood_dict(prelim)\n",
    "    \n",
    "hist_dat = {0:[],1:[],10:[],50:[],100:[],250:[],500:[],750:[],1000:[]}\n",
    "\n",
    "vector_choices = []\n",
    "dfs_to_plot=[]\n",
    "\n",
    "for file in glob.iglob('T69A_files/*.fcs'):\n",
    "    f = str(file).split('_')\n",
    "    pattern = re.compile('\\d+')\n",
    "    \n",
    "        # Library number\n",
    "    match  = re.search(pattern,f[1])\n",
    " \n",
    "    \n",
    "    library = int(match.group())\n",
    "    \n",
    "        # associated mutation rate with library number\n",
    "    mut_rate = library_mutation_rates[library]\n",
    "    \n",
    "        # Read in data as flowcal file\n",
    "    expe = FlowCal.io.FCSData(file)\n",
    "    \n",
    "    \n",
    "    s_sub_expe = expe[:,5:]\n",
    "    \n",
    "        # Calibrate data using calibration beads\n",
    "    calibrated_thing,eqs = calibration(s_sub_expe,correct_beads)\n",
    "    \n",
    "    \n",
    "        # Subtract out fusion protein and remove autofluorescence\n",
    "    normed_thing = normalize(control,calibrated_thing)\n",
    "   # normed_thing = normalize(control,calibrated_thing)\n",
    "   # normed_thing2 = normed_thing[normed_thing >0]\n",
    "   # normed_thing2 = np.log10(normed_thing2)\n",
    "   # normed_thing2 = normed_thing2.fillna(value=0)\n",
    "   # dfs_to_plot.append(normed_thing2)\n",
    "    \n",
    "\n",
    "    three_vec = normed_thing.drop(['FL4','FL5'],axis=1)\n",
    "    three_vec_values = three_vec.values\n",
    "\n",
    "    # Once fusion is gone, change negative values to just be 0 in the vector\n",
    "    three_vec_values = np.where(three_vec_values<0,0,three_vec_values)\n",
    "    vector_choices.append(three_vec_values[::-1])\n",
    "    \n",
    "    \n",
    "means = np.mean(vector_choices[0],axis=0)\n",
    "st2 = 2*(np.std(vector_choices[0],axis=0))\n",
    "max_vector = means+st2\n",
    "final_max_vector = [max(max_vector),max(max_vector),max(max_vector)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb1b134",
   "metadata": {},
   "source": [
    "# Use above vector data to normalize the space and measure neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866426ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelim = {}\n",
    "stackdata = {}\n",
    "res = prep_neighborhood_dict(prelim)\n",
    "for file in glob.iglob('T69A_files/*.fcs'):\n",
    "    f = str(file).split('_')\n",
    "    pattern = re.compile('\\d+')\n",
    "    \n",
    "        # Library number\n",
    "    match  = re.search(pattern,f[1])\n",
    "    \n",
    "    \n",
    "    library = int(match.group())\n",
    "    \n",
    "        # associated mutation rate with library number\n",
    "    mut_rate = library_mutation_rates[library]\n",
    "    \n",
    "        # Read in data as flowcal file\n",
    "    expe = FlowCal.io.FCSData(file)\n",
    "    s_sub_expe = expe[:, 5:]\n",
    "    \n",
    "        # Calibrate data using calibration beads\n",
    "    calibrated_thing,eqs = calibration(s_sub_expe,correct_beads)\n",
    "    \n",
    "        # Subtract out fusion protein and remove autofluorescence\n",
    "    normed_thing = normalize(control,calibrated_thing)\n",
    "    \n",
    "        # \n",
    "    prepped = prep(normed_thing,final_max_vector)\n",
    "    \n",
    "    result = lin_mix_model(prepped,mut_rate,mutation_rates,res)\n",
    "\n",
    "    normed_rings,old_result = norm_ring_data(result,'green')\n",
    "    \n",
    "    print('done with ' + str(library) + ' library')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30cda2",
   "metadata": {},
   "source": [
    "# Generate color neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c10634",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "radius = 1.6\n",
    "x = 1.4\n",
    "y = 0\n",
    "\n",
    "# Turn green to cyan and red to magenta\n",
    "color_blind_accessible = True \n",
    "\n",
    "\n",
    "for i in range(6,-1,-1):\n",
    "    my_ring = make_ring2(normed_rings,i,radius,50,1)\n",
    "    print(f'% dead in ring {i}: {np.round(my_ring[0][1][0],2)*100}%')\n",
    "    new_rgb = ['gray']\n",
    "    final_rgb = ['gray']\n",
    "    \n",
    "    for j,v in enumerate(my_ring[0][0]):\n",
    "        if j != 0:\n",
    "\n",
    "            new_rgb.append(colorsys.hsv_to_rgb(v[0],v[1],1))   #Change v[2] to 1 for just hue and no brightness\n",
    "    \n",
    "    \n",
    "    # If we want a color blind accessible figure, use True and use magenta and cyan\n",
    "    # else use red/green\n",
    "    if color_blind_accessible:\n",
    "        new_new_rgb = [list(tup) for tup in new_rgb[1:]]\n",
    "        for rgb in new_new_rgb:\n",
    "            if any(i> 0.7 for i in rgb):\n",
    "                rgb[2] = 0.7     # set blue channel\n",
    "                final_rgb.append(tuple(rgb))\n",
    "            else:\n",
    "                rgb[2] = max(rgb)\n",
    "                final_rgb.append(tuple(rgb))\n",
    "    \n",
    "  \n",
    "        ax.pie(my_ring[0][1],colors=final_rgb,radius=radius,frame=True)\n",
    "    \n",
    "    else:\n",
    "        ax.pie(my_ring[0][1],colors=new_rgb,radius=radius,frame=True)\n",
    "        \n",
    "\n",
    "    \n",
    "    radius = radius - 0.2\n",
    "    if i < 7:\n",
    "        color = 'white'\n",
    "    else:\n",
    "        color = 'white'\n",
    "        \n",
    "    if i != 0:    \n",
    "        if i == 6:\n",
    "            ax.text(x,y,'6+',size=9,color=color)\n",
    "    \n",
    "            x = x - 0.16\n",
    "        else:\n",
    "            ax.text(x,y,str(i),size=9,color=color)\n",
    "    \n",
    "            x = x - 0.2\n",
    "            \n",
    "    else:\n",
    "        ax.text(-0.01,y,str(i),size=9,color=color)\n",
    "\n",
    "newx = 0.0\n",
    "newy = 0\n",
    "newradius = 0.4\n",
    "\n",
    "for i in range(7):\n",
    "    ax.add_artist(Circle((0.00,y),newradius,fill=False,color='black'))\n",
    "    if i == 0:\n",
    "        newx = newx + 0.2\n",
    "    else:\n",
    "        newx = newx + 0.16\n",
    "    newradius = newradius + 0.2\n",
    "\n",
    "ax.spines.top.set_visible(False)\n",
    "ax.spines.right.set_visible(False)\n",
    "ax.spines.left.set_visible(False)\n",
    "ax.spines.bottom.set_visible(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('AncGFP_T69A_neighborhood.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecfdd52",
   "metadata": {},
   "source": [
    "# Brightness analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a506237",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors, fc, med = brightness_analysis(normed_rings,save=True,filepath='AncGFP_T69A_brightness.pdf');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41daf447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
